{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ulises Marian\n",
    "\n",
    "This project will make use of Natural Language Processing, in which I seek to build a model that analyzes sentences from the “History of Philosophy” dataset, which contains over 50 texts spanning 10 major schools of philosophy throughout thousands of years (350 BC – 1985), in order to determine which school of philosophy each sentence belongs in.\n",
    "\n",
    "I chose this topic due to multiple reasons:\n",
    "<br>1.- I wanted to create a model that would be able to classify data among multiple labels, rather than just two labels (\"yes\" or \"no\"). And in this dataset, there will be 13 labels. So, I am vary curious to see how accurate the model is.\n",
    "<br>2.- The fact that the input data (texts) encompass data from BC until 1985, is simply astonishing. Being able to use (philosophy) data spanning thousands of years, speaks of the legacy of humanity and philosophy, of human thought and development. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File: philosophy_data.csv\n",
    "<br>Source: https://www.kaggle.com/kouroshalizadeh/history-of-philosophy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ulisesmarian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt') \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This is where I will import the file \"philosophy_data.csv\",\n",
    "<br> and show you how it looks before making any modifications to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (360808, 11)\n",
      "number of rows: 360808\n",
      "number of columns: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>school</th>\n",
       "      <th>sentence_spacy</th>\n",
       "      <th>sentence_str</th>\n",
       "      <th>original_publication_date</th>\n",
       "      <th>corpus_edition_date</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>sentence_lowered</th>\n",
       "      <th>tokenized_txt</th>\n",
       "      <th>lemmatized_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>125</td>\n",
       "      <td>what's new, socrates, to make you leave your ...</td>\n",
       "      <td>['what', 'new', 'socrates', 'to', 'make', 'you...</td>\n",
       "      <td>what be new , Socrates , to make -PRON- lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>69</td>\n",
       "      <td>surely you are not prosecuting anyone before t...</td>\n",
       "      <td>['surely', 'you', 'are', 'not', 'prosecuting',...</td>\n",
       "      <td>surely -PRON- be not prosecute anyone before ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>74</td>\n",
       "      <td>the athenians do not call this a prosecution b...</td>\n",
       "      <td>['the', 'athenians', 'do', 'not', 'call', 'thi...</td>\n",
       "      <td>the Athenians do not call this a prosecution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>21</td>\n",
       "      <td>what is this you say?</td>\n",
       "      <td>['what', 'is', 'this', 'you', 'say']</td>\n",
       "      <td>what be this -PRON- say ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>101</td>\n",
       "      <td>someone must have indicted you, for you are no...</td>\n",
       "      <td>['someone', 'must', 'have', 'indicted', 'you',...</td>\n",
       "      <td>someone must have indict -PRON- , for -PRON- ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title author school  \\\n",
       "0  Plato - Complete Works  Plato  plato   \n",
       "1  Plato - Complete Works  Plato  plato   \n",
       "2  Plato - Complete Works  Plato  plato   \n",
       "3  Plato - Complete Works  Plato  plato   \n",
       "4  Plato - Complete Works  Plato  plato   \n",
       "\n",
       "                                      sentence_spacy  \\\n",
       "0   What's new, Socrates, to make you leave your ...   \n",
       "1  Surely you are not prosecuting anyone before t...   \n",
       "2  The Athenians do not call this a prosecution b...   \n",
       "3                              What is this you say?   \n",
       "4  Someone must have indicted you, for you are no...   \n",
       "\n",
       "                                        sentence_str  \\\n",
       "0   What's new, Socrates, to make you leave your ...   \n",
       "1  Surely you are not prosecuting anyone before t...   \n",
       "2  The Athenians do not call this a prosecution b...   \n",
       "3                              What is this you say?   \n",
       "4  Someone must have indicted you, for you are no...   \n",
       "\n",
       "   original_publication_date  corpus_edition_date  sentence_length  \\\n",
       "0                       -350                 1997              125   \n",
       "1                       -350                 1997               69   \n",
       "2                       -350                 1997               74   \n",
       "3                       -350                 1997               21   \n",
       "4                       -350                 1997              101   \n",
       "\n",
       "                                    sentence_lowered  \\\n",
       "0   what's new, socrates, to make you leave your ...   \n",
       "1  surely you are not prosecuting anyone before t...   \n",
       "2  the athenians do not call this a prosecution b...   \n",
       "3                              what is this you say?   \n",
       "4  someone must have indicted you, for you are no...   \n",
       "\n",
       "                                       tokenized_txt  \\\n",
       "0  ['what', 'new', 'socrates', 'to', 'make', 'you...   \n",
       "1  ['surely', 'you', 'are', 'not', 'prosecuting',...   \n",
       "2  ['the', 'athenians', 'do', 'not', 'call', 'thi...   \n",
       "3               ['what', 'is', 'this', 'you', 'say']   \n",
       "4  ['someone', 'must', 'have', 'indicted', 'you',...   \n",
       "\n",
       "                                      lemmatized_str  \n",
       "0     what be new , Socrates , to make -PRON- lea...  \n",
       "1   surely -PRON- be not prosecute anyone before ...  \n",
       "2   the Athenians do not call this a prosecution ...  \n",
       "3                          what be this -PRON- say ?  \n",
       "4   someone must have indict -PRON- , for -PRON- ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"philosophy_data.csv\", encoding='ISO-8859-1')\n",
    "print(f\"dataframe shape: {data.shape}\")\n",
    "print(f\"number of rows: {data.shape[0]}\")\n",
    "print(f\"number of columns: {data.shape[1]}\")\n",
    "set(data.original_publication_date)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For the purposes of this project, where I will do the data cleaning for NLP, I will drop all the columns that I don't need. \n",
    "<br>Create the X variable from the DataFrame. \n",
    "<br>Print the size of X and the first five lines of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360808, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is this you say?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sentence_str\n",
       "0   What's new, Socrates, to make you leave your ...\n",
       "1  Surely you are not prosecuting anyone before t...\n",
       "2  The Athenians do not call this a prosecution b...\n",
       "3                              What is this you say?\n",
       "4  Someone must have indicted you, for you are no..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.sentence_str.to_frame()\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. See how many sentences per school of philosophy there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plato 38366\n",
      "stoicism 2535\n",
      "empiricism 19931\n",
      "analytic 55425\n",
      "rationalism 22949\n",
      "phenomenology 28573\n",
      "german_idealism 42136\n",
      "nietzsche 13548\n",
      "capitalism 18194\n",
      "continental 33779\n",
      "feminism 18635\n",
      "aristotle 48779\n",
      "communism 17958\n"
     ]
    }
   ],
   "source": [
    "for school in set(data[\"school\"]):\n",
    "    print(school,len(data[data[\"school\"]==school]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create the y variable from the DataFrame.\n",
    "<br>Print the size of Y and the first five lines of Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360808,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    plato\n",
       "1    plato\n",
       "2    plato\n",
       "3    plato\n",
       "4    plato\n",
       "Name: school, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.school\n",
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Pre-process data\n",
    "<br>The tokenizer separates the text (sentences) into words (keeping only those that are alphabetic characters, thus eliminating those that contain numbers, for example)\n",
    "<br> *I will convert all the letters/sentences to lowercase. \n",
    "<br> *Then, I will remove all stop words (e.g., 'an', 'the', 'to', 'that'), because they usually don't help the model in finding the meaning of the words/sentences. Plus, eliminating them, reduces the already huge amount of data.\n",
    "<br>  *Similarly, in order to further reduce the amount of words to analyze, I extract the stem of each word. So that words that share the same root can be grouped together and counted once. \n",
    "<br>  *The final product is a dataframe with all the stems of the words in lowercase, and without stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ulisesmarian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new socrat make leav usual haunt lyceum spend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sure prosecut anyon king archon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>athenian call prosecut indict euthyphro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>someon must indict go tell indict someon els</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sentence_str\n",
       "0  new socrat make leav usual haunt lyceum spend ...\n",
       "1                    sure prosecut anyon king archon\n",
       "2            athenian call prosecut indict euthyphro\n",
       "3                                                say\n",
       "4       someon must indict go tell indict someon els"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "tokenizer = RegexpTokenizer(\"[a-zA-Z]+\")  #letters only\n",
    "\n",
    "for i,sentence in enumerate(X.sentence_str):\n",
    "    w = tokenizer.tokenize(sentence.lower())         # separate into words and lowercase each word\n",
    "    w = [word for word in w if word not in stop_words]    # remove stop words\n",
    "    w = [stemmer.stem(word) for word in w]    # find stem of each word\n",
    "    w = ' '.join(w)         # join back into a string\n",
    "    X.sentence_str[i] = w\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Since ML models need numbers to work, I hereby convert the strings in X into vectors (the CountVectorizer counts the frequency of each word) of numbers.\n",
    "<br> Show the size of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360808, 90797)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X[\"sentence_str\"])    \n",
    "X_vectors = vect.transform(X[\"sentence_str\"])\n",
    "\n",
    "X\n",
    "print(X_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 7. Split the dataset into training and testing sets and show the size of the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288646, 60482) (288646,) (72162, 60482) (72162,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vectors,y,test_size=0.2)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Use the Multinomial Naive Bayes model to train, then test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Show the accuracy of the model by displaying the accuracy score, confusion matrix, and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7187300795432499\n",
      "0.7170341025208494\n",
      "[[8762  406   53   47  237  156   69  473   25  264  467  129   17]\n",
      " [ 565 7312  101   35   99  128   81  346   29   64  894  148    3]\n",
      " [ 113   67 3082  127   57   80   30   29    9    6   70   20    1]\n",
      " [ 111   90  348 2511  124   30  104   62   36   27  105   18    8]\n",
      " [ 363  231   75  131 4599   55  161  418   61  291  184  113    5]\n",
      " [ 251  243   47    7   44 2786   45  182   21   24  148  197    5]\n",
      " [  99  158   36   91  174   81 2508   81   74   54  263   86    2]\n",
      " [ 476  256   42   61  167   72   63 6627   47  226  232  124   12]\n",
      " [ 127  172   23   25  128   43  107  118 1552   42  272   93   11]\n",
      " [ 480  171   13   43  329   53   50  596   29 3675  164   79   10]\n",
      " [ 617  903   72   34   89   59  103  166   24   60 5452  133    2]\n",
      " [ 283  375   17   13   66  266   57  264   24   48  236 2905   30]\n",
      " [   9   80    6    2    4   84    4   13   88    3   73   25   94]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. The results show us that the model is not very accurate (71.8%). It could definitely be worse, but it could also be better. On the other hand, considering that all the texts, and thus sentences, and their corresponding labels are about the same topic, philosophy, then the model did well. \n",
    "<br> If the topics would've varied, for instance, if there had also been a text about biology, another one about baseball, another one about astronomy, then probably the predictions would've been more accurate. But in the dataset used for this model, it was all philosophy, despite the fact that \"the schools of philosophy\" varied, as there were 13, but they were nevertheless philosophy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "The model that I've created to predict what school of philosophy each sentence from the “History of Philosophy” dataset belongs in, could certainly be improved. Thinking that the model has a 28.2% probabilty of being wrong could indeed be a source of concern. But if this model is simply used as a reference, taking into account that all the sentences are within the realm of philosophy, and that it is data within a 2000+ years time frame(350 BC – 1985), saying that the model isn't good, would be an understatement.\n",
    "\n",
    "How to make make the model more accurate?\n",
    "I wonder if the translations of the above (texts) sentences in other languages, such as German, would result in a more accurate model. Since it often happens that certain words cannot be directly translated into other languages, such as from German to English. Ironically, this happens often at the philosophical/emotional/intangible level. E.g., \"Fernweh\", \"Zeitgeist\", \"Weltanschauung\".\n",
    "\n",
    "Another option that comes to mind is that if instead of trying to predict each sentence separately, what if pairing them up, that is, putting two sentences together in each row, would result in a higher accuracy. Especially considering the fact that all the sentences are about philosophy, thus expanding the amount of words in a 'sentence' could increase the chances that a 'keyword' related to a certain school of philosophy be within each sentence pair.\n",
    "\n",
    "Another option is to add more data.\n",
    "As we can see from #3 (output copied below), Stoicism only has 2535 sentences, as opposed to Aristotle (48779)\n",
    "or german_idealism (42136). Also Nietzsche (13548) is low, as well as the rest of those that are below 20,000.\n",
    "\n",
    "plato 38366\n",
    "stoicism 2535\n",
    "empiricism 19931\n",
    "analytic 55425\n",
    "rationalism 22949\n",
    "phenomenology 28573\n",
    "german_idealism 42136\n",
    "nietzsche 13548\n",
    "capitalism 18194\n",
    "continental 33779\n",
    "feminism 18635\n",
    "aristotle 48779\n",
    "communism 17958\n",
    "\n",
    "Or, on the other hand, to reduce the data. That is, to reduce the amount of sentences of all those that are, e.g.,  over 35,000 to under 35,000, or perhaps reduce all those that are greater than 20,000 to 20,000. Resulting in a more balanced input accross each label.\n",
    "\n",
    "\n",
    "\n",
    "Lastly, maybe removing the stop words had a negative impact in the accuracy of the model. Nonetheless, not removing them would have resulted in a much slower algorithm/model.\n",
    "\n",
    "Similarly, the tokenizer could potentially have a direct impact on the result (accuracy of the model). Eliminating anything that is not alphabetical, like numbers, probably results in an important loss of information. For instance, in this particular dataset, the numbers might often be years, thus those years would potentially be a reference to a school of philosophy, an era, a philosopher, etc.\n",
    "\n",
    "#It's very interesting to see, after doing the analysis and conclusion, that even the (apparently) most mundane tasks (such as selecting the tokenizer, or stopwords) could have a huge impact on the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
